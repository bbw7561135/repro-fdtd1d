{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jupyter Notebook Example\n\nCredit: This is slightly modified from examples used in the FSCI 2017 Computational Reproducibility Day (https://osf.io/sbnz7/), which was created by Courtney Soderberg and Jennifer Smith from the Center for Open Science. \n"},{"metadata":{},"cell_type":"markdown","source":"# Setting up the notebook\n\n## Lets get started\n\nThe notebook is built up from separate editable areas, or cells.\n\nA new notebook contains a single *code* cell.\n\nAdd a line of code and execute it by:\n* *clicking the run button*, or\n* click in the cell, and press shift-return"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('hello world')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Navigating and Selecting Cells\n\nTo select a cell, click on it. The selected cell will be surrounded by a box with the left hand side highlighted.\n\nMove the selection focus to the cell above/below using the keyboard up/down arrow keys.\n\nAdditionally select adjacent cells using SHIFT-UP ARROW or SHIFT-DOWN ARROW.\n\n## Managing Cells - Add, Delete, Reorder\n\nAdd a new cell to the notebook by:\n* click the + button on the toolbar\n* Insert -> Insert Cell Above or ESC-A\n* Insert -> Insert Cell Below or ESC-B\n\nDelete a cell by selecting it and:\n* click the scissors button on the toolbar\n* Edit -> Delete cells or ESC-X\n\nUndelete the last deleted cell:\n* Edit -> Undo Delete cells or ESC-Z\n\nEach cell has a cell history associated with it. Use CMD-Z to step back through previous cell contents.\n\nReorder cells by:\n* moving them up and down the notebook using the up and down arrows on the toolbar\n* Edit -> Move Cell Up or Edit -> Move Cell Down\n* cutting and pasting them:\n    * Edit - >Cut or Edit->Paste Cells Above or Edit->Paste Cells Below on the toolbar\n\nYou can also copy selected cells from the toolbar, Edit -> Copy Cells or ESC-C.\n## More resources\n\n[More stuff you can do in notebooks](https://towardsdatascience.com/how-to-effortlessly-optimize-jupyter-notebooks-e864162a06ee)"},{"metadata":{},"cell_type":"markdown","source":"## About Libraries in Python\n\nLets use our first code cell to import a library. A library in Python contains a set of tools (called functions) that perform tasks on our data. Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project. Once a library is imported, it can be used or called to perform many tasks.\n\nPython doesn’t load all of the libraries available to it by default. We have to add an import statement to our code in order to use library functions. To import a library, we use the syntax `import libraryName`. If we want to give the library a nickname to shorten the command, we can add `as nickNameHere`. An example of importing the Pandas library using the common nickname `pd` is below.\n\n**`import`** `pandas` **`as`** `pd`\n\n## The Pandas Library\n\nOne of the best options for working with tabular data in Python is the Python Data Analysis Library (a.k.a. Pandas). The Pandas library is built on top of the NumPy package (another Python library). Pandas provides data structures, produces high quality plots with matplotlib, and integrates nicely with other libraries that use NumPy arrays. Those familiar with spreadsheets should become comfortable with Pandas data structures.\n  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each time we call a function that’s in a library, we use the syntax `LibraryName.FunctionName`. Adding the library name with a `.` before the function name tells Python where to find the function. In the example above, we have imported Pandas as `pd`. This means we don’t have to type out `pandas` each time we call a Pandas function.\n\nSee this free [Pandas cheat sheet](https://www.datacamp.com/community/blog/python-pandas-cheat-sheet) from DataCamp for the most common Pandas commands. "},{"metadata":{},"cell_type":"markdown","source":"## Markdown\n\nWe're seen how we can have coding cells and show their output below them, but what about that plain language I mentioned? We can added another type of cell, a Markdown cell that contains narrative text. Markdown is a popular markup language that is a superset of HTML. To learn more, see [Jupyter's Markdown guide](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html) or revisit the [Reproducible Research lesson on Markdown](https://github.com/Reproducible-Science-Curriculum/introduction-RR-Jupyter/blob/master/notebooks/Navigating%20the%20notebook%20-%20instructor%20script.ipynb).\n\nLets add a markdown cell above our library imports. Do to this:\n\n* Change the cell type using the drop down list in the toolbar, or by using the ESC-M keyboard shortcut.\n* To \"open\" or select a markdown cell for editing, double click the cell.\n* View the rendered markdown by running the cell:\n\nMarkdown cells can contain:\n\n* headings\n    Prefix a line of text in a markdown cell by one or more # signs, followed by a space, to specify the level of the heading required.\n# Heading 1\n## Heading 2\n...\n###### Heading 6"},{"metadata":{},"cell_type":"markdown","source":"# Getting data into the notebook\n\nWe will begin by locating and reading our data which are in a table format as a tab-delimited file. We will use Pandas’ `read_csv` function to pull the file directly into a `DataFrame`.\n\n## What’s a `DataFrame`?\nA `DataFrame` is a 2-dimensional data structure that can store in columns data of different types (including characters, integers, floating point values, factors and more). It is similar to a spreadsheet or a SQL table or data.frame in R. A `DataFrame` always has an index (0-based). An index refers to the position of an element in the data structure.\n\nNote that we use `pd.read_csv`, not just `read_csv` or `pandas.read_csv`, because we imported Pandas as `pd`.\n\nIn our original file, the columns in the data set are separated by a TAB. We need to tell the `read_csv` function in Pandas that that is the delimiter with `sep = ‘\\t’`.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://osf.io/z274d/download\"\n#You can also read your table in from a file directory\ngapminder = pd.read_csv(url, sep = \"\\t\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first thing to do when loading data into the notebook is to actually \"look\" at it.  How many rows and columns are there?  What types of variables are in it and what values can they take?\n\nThere are usually too many rows to print to the screen.  By default, when you type the name of the `DataFrame` and run a cell, Pandas knows to not print the whole thing.  Instead, you will see the first and last few rows with dots in between.  A neater way to see a preview of the dataset is the `head()` method.  Calling `dataset.head()` will display the first 5 rows of the data.  You can specify how many rows you want to see as an argument, like `dataset.head(10)`.  The `tail()` method does the same with the last rows of the `DataFrame`."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sometimes the table has too many columns to print on screen. Calling `df.columns.values` will print all the column names in an array."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder.columns.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assess the structure and cleanliness\n\n\n## How many rows and columns are in the data?\nWe often want to know how many rows and columns are in the data -- what is the \"shape\" of the `DataFrame`. Shape is an attribute of the `DataFrame`. Pandas has a convenient way for getting that information by using `DataFrame.shape`  (using `DataFrame` here as a generic name for your `DataFrame`). This returns a tuple (immutable values separated by commas) representing the dimensions of the `DataFrame` (rows, columns).<p>\nTo get the shape of the gapminder `DataFrame`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can learn even more about our `DataFrame`. The `info()` method gives a few useful pieces of information, including the shape of the `DataFrame`, the variable type of each column, and the amount of memory stored.\n\nThe output from `info()` displayed below shows that the fields ‘year’ and ‘pop’ (population) are represented as ‘float’ (that is: numbers with a decimal point). This is not appropriate: year and population should be integers or whole numbers. We can change the data-type with the function `astype()`. The code for `astype()` is shown below; however, we will change the data types later in this lesson."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `describe()` method will take the numeric columns and provide a summary of their values. This is useful for getting a sense of the ranges of values and seeing if there are any unusual or suspicious numbers.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `DataFrame` function `describe()` just blindly looks at all numeric variables. We wouldn't actually want to take the mean year. Additionally, we obtain ‘NaN’ values for our quartiles. This suggests we might have missing data which we can (and will) deal with shortly when we begin to clean our data.\n\nFor now, let's pull out only the columns that are truly continuous numbers (i.e. ignore the description for ‘year’). This is a preview of selecting columns from the data; we'll talk more about how to do it later in the lesson."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder[['pop', 'lifeexp', 'gdppercap']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{},"cell_type":"markdown","source":"## Referencing objects vs copying objects\nBefore we get started with cleaning our data, let's practice good data hygiene by first creating a copy of our original data set. Often, you want to leave the original data untouched.  To protect your original, you can make a copy of your data (and save it to a new `DataFrame` variable) before operating on the data or a subset of the data.  This will ensure that a new version of the original data is created and your original is preserved.\n\n###### Why this is important\nSuppose you take a subset of your `DataFrame` and store it in a new variable, like `gapminder_early = gapminder[gapminder['year'] < 1970]`.  Doing this does not actually create a new object. Instead, you have just given a name to that subset of the original data: `gapminder_early`. This subset still points to the original rows of `gapminder`.  Any changes you make to the new `DataFrame` `gapminder_early` will appear in the corresponding rows of your original `gapminder` `DataFrame` too.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder = pd.read_csv(url, sep = \"\\t\")\ngapminder_copy = gapminder.copy()\ngapminder_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling Missing Data\n\nMissing data (often denoted as 'NaN'- not a number- in Pandas, or as 'null') is an important issue to handle because Pandas cannot compute on rows or columns with missing data. 'NaN' or 'null' does not mean the value at that position is zero, it means that there is no information at that position. Ignoring missing data doesn't make it go away. There are different ways of dealing with it which include:\n\n* analyzing only the available data (i.e. ignore the missing data)\n* input the missing data with replacement values and treating these as though they were observed\n* input the missing data and account for the fact that these were inputed with uncertainty (ex: create a new boolean variable so you know that these values were not actually observed)\n* use statistical models to allow for missing data--make assumptions about their relationships with the available data as necessary\n\nFor our purposes with the dirty gapminder data set, we know our missing data is excess (and unnecessary) and we are going to choose to analyze only the available data. To do this, we will simply remove rows with missing values.\n\nThis is incredibly easy to do because Pandas allows you to either remove all instances with null data or replace them with a particular value.\n\n`df = df.dropna()` drops rows with any column having NA/null data.  `df = df.fillna(value)` replaces all NA/null data with the argument `value`.\n\nFor more fine-grained control of which rows (or columns) to drop, you can use `how` or `thresh`. These are more advanced topics and are not covered in this lesson; you are encouraged to explore them on your own."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy = gapminder_copy.dropna()\ngapminder_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Changing Data Types\nWe can change the data-type with the function `astype()`. The code for `astype()` is shown below."},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Subsetting\n\nWe can subset (or slice) by giving the numbers of the rows you want to see between square brackets.\n\n*REMINDER:* Python uses 0-based indexing. This means that the first element in an object is located at position 0. this is different from other tools like R and Matlab that index elements within objects starting at 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the first 15 rows\ngapminder_copy[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the last 10 rows\ngapminder_copy[-10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subsetting can also be done by selecting for a particular column or for a particular value in a column; for instance select the rows that have ‘africa’ in the column ‘continent. Note the double equal sign: single equal signs are used in Python to assign something to a variable. The double equal sign is a comparison: the variable to the left has to be exactly equal to the string to the right."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select for a particular column\ngapminder_copy['year']\n\n#this syntax, calling the column as an attribute, gives you the same output\ngapminder_copy.year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summarize and plot\n\nSummaries (but can’t *say* statistics…)\n* Sort data\n* Can make note about using numpy functions, dif between `DataFrame` and `array`\nGood Plots for the data/variable type\n\n\n\nPlots \n* of subsets, \n* single variables\n* pairs of variables\n* Matplotlib syntax (w/ Seaborn for defaults (prettier, package also good for more analysis later...))\n\nExploring is often iterative - summarize, plot, summarize, plot, etc. - sometimes it branches…\n"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# Summarizing data\n\nRemember that the `info()` method gives a few useful pieces of information, including the shape of the `DataFrame`, the variable type of each column, and the amount of memory stored. We can see many of our changes (continent and country columns instead of region, higher number of rows, etc.) reflected in the output of the `info()` method."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also saw above that the `describe()` method will take the numeric columns and give a summary of their values. We have to remember that we changed the column names and this time it shouldn't have NaNs."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy[['pop', 'lifeexp', 'gdppercap']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More summaries\n\nWhat if we just want a single value, like the mean of the population? We can call mean on a single column this way:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy['pop'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we want to know the mean population by _continent_? Then we need to use the Pandas `groupby()` method and tell it which column we want to group by.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy[['continent', 'pop']].groupby(by='continent').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we wanted a new `DataFrame` that just contained these summaries? This could be a table in a report, for example."},{"metadata":{"trusted":true},"cell_type":"code","source":"continent_mean_pop = gapminder_copy[['continent', 'pop']].groupby(by='continent').mean()\ncontinent_mean_pop = continent_mean_pop.rename(columns = {'pop':'meanpop'})\ncontinent_row_ct = gapminder_copy[['continent', 'country']].groupby(by='continent').count()\ncontinent_row_ct = continent_row_ct.rename(columns = {'country':'nrows'})\ncontinent_median_pop = gapminder_copy[['continent', 'pop']].groupby(by='continent').median()\ncontinent_median_pop = continent_median_pop.rename(columns = {'pop':'medianpop'})\ngapminder_summs = pd.concat([continent_row_ct,continent_mean_pop,continent_median_pop], axis=1)\ngapminder_summs = gapminder_summs.rename(columns = {'y':'year'})\ngapminder_summs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization with `matplotlib`\n\n[matplotlib](http://matplotlib.org) is Python's main visualization \nlibrary. It provides a range of tools for constructing plots and numerous \nhigh-level plotting libraries (e.g., [Seaborn](http://seaborn.pydata.org)) are \nbuilt with matplotlib in mind. When we were in the early stages of setting up \nour analysis, we loaded these libraries like so:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Consider the above three commands to be essential practice for plotting (as\nessential as **`import`** `pandas` **`as`** `pd` is for data munging).*\n\nNow, let's turn to data visualization. In order to get a feel for the properties\nof the data set we are working with, data visualization is key. While, we will\nfocus only on the essentials of how to properly construct plots in univariate\nand bivariate settings here, it's worth noting that both matplotlib and Seaborn\nsupport a diversity of plots: [matplotlib \ngallery](http://matplotlib.org/gallery.html), [Seaborn\ngallery](http://seaborn.pydata.org/examples/). \n\n\n---"},{"metadata":{},"cell_type":"markdown","source":"### Single variables\n\n* __Histograms__ - provide a quick way of visualizing the distribution of numerical\n  data, or the frequencies of observations for categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import numpy as npa\nplt.hist(gapminder_copy['lifeexp'])\nplt.xlabel('lifeexp')\nplt.ylabel('count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm, something does look right.  Let's check the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy['lifeexp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_copy['lifeexp'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, it seems that there's a 999999 value that was used to indicate **something**, and it's throwing off the histogram. So let's remove rows that don't have a life expentency between 0 and 100, and then try again"},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_clean = gapminder_copy[gapminder_copy['lifeexp'].between(0, 100)]\ngapminder_clean['lifeexp'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(gapminder_clean['lifeexp'])\nplt.xlabel('lifeexp')\nplt.ylabel('count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* __Boxplots__ - provide a way of comparing the summary measures (e.g., max, min,\n  quartiles) across variables in a data set. Boxplots can be particularly useful with larger data sets.\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='year', y='lifeexp', data = gapminder_clean)\nplt.xlabel('year')\nplt.ylabel('lifeexp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pairs of variables\n\n* __Scatterplots__ - visualization of relationships across two variables..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# example plot goes here\n\nplt.scatter(gapminder_clean['gdppercap'], gapminder_clean['lifeexp'])\nplt.xlabel('gdppercap')\nplt.ylabel('lifeexp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(gapminder_clean['gdppercap'], gapminder_clean['lifeexp'])\nplt.xscale('log')\nplt.xlabel('gdppercap')\nplt.ylabel('lifeexp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving your plots as image files  \nIf you'd like to save your plots as an image file, you can run `fig.savefig('my_figure.png')` where `\"my_figure\"` is the file name.    "},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# Putting it all together\n\nOn your own or with a partner, using the techniques you've learned in this lesson, try to create a plot of life expectancy in Canada during the 1950s and 1960s. We've provided headers to guide you through the process."},{"metadata":{},"cell_type":"markdown","source":"#### Import your data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Describe your data set here using *Markdown*\nWhat is the general shape of your `DataFrame`? What are the datatypes? Are there missing values? What questions do you have about your data set and how will you answer those questions?"},{"metadata":{},"cell_type":"markdown","source":"Answers:"},{"metadata":{},"cell_type":"markdown","source":"#### Create a subset of the data for just Canada and for years between 1950 and 1969"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create a plot of life expectancy by year. Is there anything wrong?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fix the 99999 coding error, rerun the plot and save it. *Hint* try using the df.set_values() command to change the value"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}